{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Author: Yury Kashnitsky, Data Scientist at Mail.Ru Group\n",
    "\n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6. Part 1\n",
    "### <center> Beating benchmarks in \"Catch Me If You Can: Intruder Detection through Webpage Session Tracking\"\n",
    "    \n",
    "[Competition](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2). The task is to beat \"Assignment 6 baseline\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = ('../../data')\n",
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_sessions.csv'), index_col='session_id')\n",
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_sessions.csv'), index_col='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate target feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# Load websites dictionary\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "print(u'Websites total:', sites_dict.shape[0])\n",
    "sites_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Tf-Idf features based on sites. You can use `ngram_range`=(1, 3) and `max_features`=100000 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=100000)\n",
    "tfidf12 = TfidfVectorizer(ngram_range=(1, 3), max_features=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем добавить разницу между time1 и time10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['time1t'] = train_df['time1'].apply(lambda x : datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_time(row):\n",
    "    res = datetime.strptime(row.time1,'%Y-%m-%d %H:%M:%S') - datetime.strptime(row.time1,'%Y-%m-%d %H:%M:%S')\n",
    "    try:\n",
    "        res = datetime.strptime(row.time10,'%Y-%m-%d %H:%M:%S') - datetime.strptime(row.time1,'%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        pass\n",
    "    return res\n",
    "\n",
    "def delta_time12(row):\n",
    "    res = datetime.strptime(row.time1,'%Y-%m-%d %H:%M:%S') - datetime.strptime(row.time1,'%Y-%m-%d %H:%M:%S')\n",
    "    try:\n",
    "        res = datetime.strptime(row.time2,'%Y-%m-%d %H:%M:%S') - datetime.strptime(row.time1,'%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        pass\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['delta'] = full_df.apply(delta_time, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['delta12'] = full_df.apply(delta_time12, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:00:46.634305')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.target == 1].delta.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:01:49.528766')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.target == 0].delta.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:01:48.959007')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.delta.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.delta.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df[train_df.target == 0].delta.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df[train_df.target == 1].delta.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltaOHE = pd.get_dummies(full_df.delta)\n",
    "Delta12OHE = pd.get_dummies(full_df.delta12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 21), (82797, 20))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253561"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull_df = full_df[sites]\n",
    "Xfull_df = Xfull_df.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull = Xfull_df.to_string(index=False).split('\\n')[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253561"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xfull[:idx_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(Xtrain_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull_ifidf = tfidf.fit_transform(Xfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull_ifidf12 = tfidf12.fit_transform(Xfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<336358x100000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4759727 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfull_ifidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<336358x12000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3732499 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfull_ifidf12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add features based on the session start time: hour, whether it's morning, day or night and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "def getMDAN(data):\n",
    "    time = datetime.strptime(data,'%Y-%m-%d %H:%M:%S')\n",
    "    if (time.hour >= 0) & (time.hour < 8):\n",
    "        return 1\n",
    "    elif (time.hour >= 8) & (time.hour < 16):\n",
    "        return 2\n",
    "    elif (time.hour >= 16) & (time.hour < 23):\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "PartsOfDay = full_df['time1'].apply(getMDAN)\n",
    "PartsOfDayOHE = pd.get_dummies(PartsOfDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeekDays = full_df['time1'].apply(lambda x : datetime.strptime(x,'%Y-%m-%d %H:%M:%S').isoweekday())\n",
    "WeekDaysOHE1 = pd.get_dummies(WeekDays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "StartHour = full_df['time1'].apply(lambda x : datetime.strptime(x,'%Y-%m-%d %H:%M:%S').hour)\n",
    "StartHourOHE = pd.get_dummies(StartHour)\n",
    "SitesHoursOHE12 = hstack([Xfull_ifidf12,StartHourOHE])\n",
    "DeltasOHE12 = hstack([SitesHoursOHE12, DeltaOHE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SitesDaysPartsOHE12 = hstack([DeltasOHE12,PartsOfDayOHE,WeekDaysOHE1.drop([3,6,7], axis=1),Delta12OHE])\n",
    "# SitesDaysPartsOHE12 = hstack([DeltasOHE12,WeekDaysOHE1.drop([3,6,7], axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "SitesHoursOHE = hstack([Xfull_ifidf,StartHourOHE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "SitesHoursOHE12drop = hstack([Xfull_ifidf12,StartHourOHE.drop([16,17,18], axis=1)])\n",
    "DeltasOHE12drop = hstack([SitesHoursOHE12drop, DeltaOHE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltasOHE = hstack([SitesHoursOHE, DeltaOHE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale this features and combine then with Tf-Idf based on sites (you'll need `scipy.sparse.hstack`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validation with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "def calcScore(X,y,C):\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "        y_train1, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        lr = LogisticRegression(C=C, random_state=17, n_jobs=-1).fit(X_train, y_train1)\n",
    "        # Prediction for validation set\n",
    "        y_pred = lr.predict_proba(X_test)[:, 1]\n",
    "        # Calculate the quality\n",
    "#         print(y_train1.shape, y_test.shape)\n",
    "        score = roc_auc_score(y_test, y_pred)\n",
    "        print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcScore(Xfull_ifidf[:idx_split], y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94340095387900647"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, Xfull_ifidf[:idx_split], y, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97512292128486155"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, SitesHoursOHE.tocsr()[:idx_split], y, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97319879771730233"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, SitesHoursOHE12.tocsr()[:idx_split], y, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97226883897277949"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, DeltasOHE12.tocsr()[:idx_split], y, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97389228315846799"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, DeltasOHE.tocsr()[:idx_split], y, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754504242499088"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, SitesDaysPartsOHE12.tocsr()[:idx_split], y, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97549451045162139"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, SitesDaysPartsOHE12.tocsr()[:idx_split], y, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(lr, Xfull_ifidf[:idx_split], y, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "#вначале попробуем проверить в стиле baseline\n",
    "def get_auc_lr_valid(X, y, C=1.0, seed=17, ratio = 0.9):\n",
    "    # Split the data into the training and validation sets\n",
    "    idx = int(round(X.shape[0] * ratio))\n",
    "    # Classifier training\n",
    "    lr = LogisticRegression(C=C, random_state=seed, n_jobs=-1).fit(X[:idx, :], y[:idx])\n",
    "    # Prediction for validation set\n",
    "    y_pred = lr.predict_proba(X[idx:, :])[:, 1]\n",
    "    # Calculate the quality\n",
    "    score = roc_auc_score(y[idx:], y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98011268738404933"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(SitesHoursOHE.tocsr()[:idx_split], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97665472256625574"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(SitesHoursOHE12.tocsr()[:idx_split], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for the test set and form a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1.0, random_state=17, n_jobs=-1).fit(SitesHoursOHE.tocsr()[:idx_split, :], y)\n",
    "lr12 = LogisticRegression(C=1.0, random_state=17, n_jobs=-1).fit(SitesHoursOHE12.tocsr()[:idx_split, :], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "test_pred = lr.predict_proba(SitesHoursOHE.tocsr()[idx_split:])[:, 1]\n",
    "test_pred12 = lr12.predict_proba(SitesHoursOHE12.tocsr()[idx_split:])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_delta = LogisticRegression(C=1.0, random_state=17, n_jobs=-1).fit(DeltasOHE.tocsr()[:idx_split, :], y)\n",
    "lr_delta12 = LogisticRegression(C=1.0, random_state=17, n_jobs=-1).fit(DeltasOHE12.tocsr()[:idx_split, :], y)\n",
    "\n",
    "test_pred_delta = lr_delta.predict_proba(DeltasOHE.tocsr()[idx_split:])[:, 1]\n",
    "test_pred_delta12 = lr_delta12.predict_proba(DeltasOHE12.tocsr()[idx_split:])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_delta12drop = LogisticRegression(C=1.0, random_state=17, n_jobs=-1).fit(DeltasOHE12drop.tocsr()[:idx_split, :], y)\n",
    "test_pred_delta12drop = lr_delta12drop.predict_proba(DeltasOHE12drop.tocsr()[idx_split:])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SitesDaysPartsOHE12\n",
    "lr_delta12VK = LogisticRegression(C=7, random_state=17, n_jobs=-1).fit(SitesDaysPartsOHE12.tocsr()[:idx_split, :], y)\n",
    "test_pred_delta12VK = lr_delta12VK.predict_proba(SitesDaysPartsOHE12.tocsr()[idx_split:])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(test_pred, \"assignment6_alice_submission5_100000.csv\")\n",
    "write_to_submission_file(test_pred12, \"assignment6_alice_submission5_12000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(test_pred_delta, \"assignment6_alice_submission6_delta_100000.csv\")\n",
    "write_to_submission_file(test_pred_delta12, \"assignment6_alice_submission6_delta_12000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(test_pred_delta12drop, \"assignment6_alice_submission7_delta_12000_drop161718.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(test_pred_delta12VK, \"assignment6_alice_submission7_delta_12000_VK3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(test_pred_delta12VK, \"assignment6_alice_submission7_delta_12000_VK4+delta12.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
